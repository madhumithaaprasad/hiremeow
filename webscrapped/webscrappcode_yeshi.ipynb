{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ee629ad-21fa-467f-8394-e3e02d9c409b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\npyes\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\npyes\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\npyes\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\npyes\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\npyes\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\npyes\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\npyes\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2021.5.30)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\npyes\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\npyes\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\npyes\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\npyes\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\npyes\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\npyes\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4 pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53afe3cf-0566-4854-8c70-b5bf2f543a7b",
   "metadata": {},
   "source": [
    "IMPORTSSSSSSSSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f5e5be44-2ea9-4d1c-9938-c3a30fcc3e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad99495-8cf3-48af-9161-df4a8c1af499",
   "metadata": {},
   "source": [
    "add the website link to be scrapped here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c858c60b-1ad6-4931-9c20-27833ea9231c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.geeksforgeeks.org/microsofts-asked-interview-questions/\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e589f9-568d-4da8-b5d6-f27e0b1707d8",
   "metadata": {},
   "source": [
    "soupppppppppp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c318a611-1c2e-484a-b302-6635d5e9cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7771c853-91c0-4ef0-b975-8b7dd4e6d492",
   "metadata": {},
   "source": [
    "go to the web page , click on inspect and try to find the path to where the qs are located in the html doc. change the code and the loops based on the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "21ebce44-c42a-450a-a9c2-465ad4abf9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Dataset ID                                           Question   Category  \\\n",
      "0     #HMMIC1               Check if a Binary Tree is BST or not  Technical   \n",
      "1     #HMMIC2    Remove duplicates from a string, do it in-place  Technical   \n",
      "2     #HMMIC3  Given a rotated array which is sorted search f...  Technical   \n",
      "3     #HMMIC4  write a function that adds the numbers and sto...  Technical   \n",
      "4     #HMMIC5                                               here  Technical   \n",
      "5     #HMMIC6    Print last 10 lines of a big file or big string  Technical   \n",
      "6     #HMMIC7  Clone a linked list with next and arbitrary (o...  Technical   \n",
      "7     #HMMIC8                        Connect nodes at same level  Technical   \n",
      "8     #HMMIC9             Least common ancestor of a binary tree  Technical   \n",
      "9    #HMMIC10                                Run length encoding  Technical   \n",
      "10   #HMMIC11                      Detect cycle in a linked list  Technical   \n",
      "11   #HMMIC12  Given a sorted array of size n. Each element i...  Technical   \n",
      "12   #HMMIC13                 Check if a binary tree is balanced  Technical   \n",
      "13   #HMMIC14                        Validate a given IP address  Technical   \n",
      "14   #HMMIC15  Two of the nodes of a BST are swapped. Correct...  Technical   \n",
      "15   #HMMIC16    Draw a circle without floating point arithmetic  Technical   \n",
      "\n",
      "   Sub-Category Difficulty         Source    Company  \n",
      "0           DSA        N/A  GeeksforGeeks  Microsoft  \n",
      "1           DSA        N/A  GeeksforGeeks  Microsoft  \n",
      "2           DSA        N/A  GeeksforGeeks  Microsoft  \n",
      "3           DSA        N/A  GeeksforGeeks  Microsoft  \n",
      "4           DSA        N/A  GeeksforGeeks  Microsoft  \n",
      "5           DSA        N/A  GeeksforGeeks  Microsoft  \n",
      "6           DSA        N/A  GeeksforGeeks  Microsoft  \n",
      "7           DSA        N/A  GeeksforGeeks  Microsoft  \n",
      "8           DSA        N/A  GeeksforGeeks  Microsoft  \n",
      "9           DSA        N/A  GeeksforGeeks  Microsoft  \n",
      "10          DSA        N/A  GeeksforGeeks  Microsoft  \n",
      "11          DSA        N/A  GeeksforGeeks  Microsoft  \n",
      "12          DSA        N/A  GeeksforGeeks  Microsoft  \n",
      "13          DSA        N/A  GeeksforGeeks  Microsoft  \n",
      "14          DSA        N/A  GeeksforGeeks  Microsoft  \n",
      "15          DSA        N/A  GeeksforGeeks  Microsoft  \n"
     ]
    }
   ],
   "source": [
    "a_tags = soup.select('div.text > ul > li > a:nth-of-type(1) > span') \n",
    "\n",
    "data = []\n",
    "\n",
    "dataset_counter = 1 # for the dataset IDSSSSS\n",
    "\n",
    "for span_tag in a_tags:\n",
    "    a_tag = span_tag.find_parent('a')\n",
    "    \n",
    "    if a_tag and a_tag.has_attr('href'):\n",
    "        question_url = a_tag['href']\n",
    "        question_title = span_tag.text.strip()\n",
    "\n",
    "        # madhu generate an id like this so that we have a unique id for each question HM stands for hiremeow and the abbreviation of the company name.\n",
    "        dataset_id = f'#HMMIC{dataset_counter}'\n",
    "\n",
    "        # data for the table\n",
    "        category = 'Technical'  \n",
    "        sub_category = 'DSA' \n",
    "        difficulty = 'N/A' \n",
    "        source = 'GeeksforGeeks' \n",
    "        company = 'Microsoft' \n",
    "\n",
    "        # append to the data list :)\n",
    "        data.append([dataset_id, question_title, category, sub_category, difficulty, source, company])\n",
    "\n",
    "        dataset_counter += 1\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Dataset ID', 'Question', 'Category', 'Sub-Category', 'Difficulty', 'Source', 'Company'])\n",
    "\n",
    "# dropping the random rows, you can remove this line.\n",
    "df = df.drop(df.index[16:])\n",
    "\n",
    "df.to_csv('microsoft_interview_questions.csv', index=False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6a4d9d-3505-4817-9d77-94b5cd71306f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c7231a-a7c1-4cc3-8e6f-afee05a441a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
